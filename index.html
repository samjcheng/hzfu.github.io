<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
	<link rel="icon" type="image/x-icon" href="favicon.ico">
	<link rel="Bookmark" type="image/x-icon" href="favicon.ico">
	<link rel="apple-touch-icon" type="image/x-icon" href="favicon.png">
	<title>Homepage of Huazhu Fu </title>
	<meta name="viewport" content="width=device-width">
</head>

<body>
	<div class="wrapper" style="font-family: Helvetica, Tahoma, Arial; width:960px; margin: 0 auto; line-height:150%">

		<section>
			<table border="0" id="table1" width="100%">
				<tbody>
					<tr>
						<td>
							<p align="left">
								<img border="0" src="sub_img/wordcloud.jpeg" width="200">
							</p>
						</td>

						<td style="width:70%">
							<h1> Huazhu Fu </h1>
							<p><strong>Senior Scientist</strong><br>
								Inception Institute of Artificial Intelligence (IIAI),<br>
								Abu Dhabi, UAE.<br> <br>
								<img border="0" src="sub_img/email.jpg" height="20">
							</p>
						</td>
						
					</tr>
				</tbody>
			</table>

			I am a Senior Scientist in the Inception Institute of Artificial Intelligence (IIAI), Abu Dhabi,
			UAE. I earned my Ph.D. degree from Tianjin University in 2013, and then, worked as a
			research fellow in Nanyang Technological University (NTU) for two years. From 2015 to 2018,
			I worked as a Research Scientist in the Institute for Infocomm Research (I2R) of Agency for Science,
			Technology and Research
			(A*STAR), Singapore.
			<hr />

			<h3>
				<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a>
				Recent News:
			</h3>

			<ul>
				<li><strong>[03/2021]</strong> Two papers (<em>"Co-saliency Detection"</em> and <em>"Video shadow
						Detection"</em>) accepted to <i><strong>CVPR 2021</strong></i>.
				</li>
				<li><strong>[02/2021]</strong> One paper for <em>"Co-saliency Detection"</em> accepted to
					<i><strong>IEEE TPAMI</strong></i>.
				</li>
				<li><strong>[01/2021]</strong> One paper for <em>"Breast Lesion Segmentation"</em> accepted to
					<i><strong>MedIA</strong></i>.
				</li>
				<li><strong>[01/2021]</strong> One paper for <em>"Fundus Image Analysis Survey"</em> accepted to
					<i><strong>MedIA</strong></i>.
				</li>
				<li><strong>[01/2021]</strong> One paper for <em>"Uncertainty Estimation in Multi-view Learning"</em>
					accepted to <i><strong>ICLR 2021</strong></i>.
				</li>
				<li><strong>[01/2021]</strong> One paper for <em>"Saliency Detection Survey"</em> accepted to
					<i><strong>IEEE TPAMI</strong></i>.
				</li>
				<li><strong>...</strong></li>

			</ul>

			<hr />

			<h3>
				<a id="Research-page" class="anchor" href="#Research-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a> Research Interests:
			</h3>
			<ul>
				<li>
					<strong>Foreground Detection:</strong> saliency detection, image segmentation.
					<ul>
						<li> "Salient Object Detection in the Deep Learning Era: An In-Depth Survey" <a
								href="https://github.com/wenguanwang/SODsurvey">[Link]</a> </li>
						<li> "CoSOD3k: Co-Salient Object Detection Dataset and Benchmark" <a
								href="http://dpfan.net/CoSOD3k/">[Link]</a>
						</li>
					</ul>
				</li>
				<li>
					<strong>Multi-modal AI:</strong> multi-view learning, <font color="#E74C3C">trustworthy learning
					</font>.
				</li>
				<li>
					<strong>Medical Image Analysis:</strong>
					<font color="#E74C3C">ocular image analysis</font>, medical image/volume segmentation.
					<ul>
						<li> "Applications of Deep Learning in Fundus Images: A Review" <a
								href="https://github.com/nkicsl/Fundus_Review" target="_blank">[Link]</a></li>
						<li> "ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New Model"
							<a href="https://github.com/iMED-Lab/OCTA-Net-OCTA-Vessel-Segmentation-Network"
								target="_blank">[Code]</a>
							<a href="https://imed.nimte.ac.cn/dataofrose.html" target="_blank">[Data]</a>
						</li>
						<li> "COVID-19 Imaging-based AI Research Collection" <a
								href="https://github.com/HzFu/COVID19_imaging_AI_paper_list" target="_blank">[Link]</a>
						</li>
					</ul>
				</li>
			</ul>


			<hr />
			<h3>
				<a id="Services-page" class="anchor" href="#Services-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a> Activities:
			</h3>
			<ul>
				<li><strong>Associate Editor:</strong>
					<ul>
						<li> IEEE Transactions on Medical Imaging (2020 - present). </li>
						<li> IEEE Journal of Biomedical and Health Informatics (2020 - present). </li>
					</ul>
				</li>

				<li><strong>Conference Area Chair:</strong>
					<ul>
						<li>
							MICCAI (2021).
						</li>
					</ul>
				</li>


				<li><strong>Challenge Organizer:</strong>
					<ul>
						<li>
							"GAMMA: Glaucoma Grading from Multi-Modality Images Challenge" with the MICCAI 2021.
							[<a href="https://gamma.grand-challenge.org/" target="_blank">Link</a>]
						</li>
						<li>
							"REFUGE-2: 2nd Retinal Fundus Glaucoma Challenge" with the MICCAI 2020.
							[<a href="https://refuge.grand-challenge.org" target="_blank">Link</a>]
						</li>
						<li>
							"ADAM Automatic Detection challenge on Age-related Macular degeneration" with the ISBI 2020.
							[<a href="https://amd.grand-challenge.org" target="_blank">Link</a>]
						</li>
						<li>
							"AGE Angle closure Glaucoma Evaluation Challenge" with the MICCAI 2019.
							[<a href="https://age.grand-challenge.org/" target="_blank">Link</a>] [<a
								href="https://arxiv.org/abs/2005.02258" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"PALM PathologicAL Myopia detection from retinal images" with the ISBI 2019. [<a
								href="https://palm.grand-challenge.org" target="_blank">Link</a>]
						</li>
						<li>
							"REFUGE: Retinal Fundus Glaucoma Challenge" with the MICCAI 2018. [<a
								href="https://refuge.grand-challenge.org/" target="_blank">Link</a> ]
							[<a href="https://doi.org/10.1016/j.media.2019.101570" target="_blank">Summary Paper</a>]
						</li>
					</ul>
				</li>
				<li><strong>Workshop Chair: </strong>
					<ul>
						<li>OMIA: MICCAI Workshop on Ophthalmic Medical Image Analysis (2018 - present) [<a
								href="https://omia.grand-challenge.org" target="_blank">Link</a>]</li>
					</ul>
				</li>
			</ul>
			</p>

			<hr />


			<h3>
				<a id="Paper-pages" class="anchor" href="#Paper-pages" aria-hidden="true"><span
						class="octicon octicon-link"></span></a> Selected Publications:
			</h3>

			<h4>
				<a href="https://scholar.google.com/citations?hl=en&user=jCvUBYMAAAAJ" target="_blank">[Google Scholar
					Profile]</a> <em>for full publication list.</em>

			</h4>

			<h4>
				Preprint:
			</h4>

			<ul>
				<li>"VideoLT: Large-scale Long-tailed Video Recognition", <br>
					<em>Xing Zhang, Zuxuan Wu, Zejia Weng, <u>Huazhu Fu</u>, Jingjing Chen, Yu-Gang Jiang, and Larry Davis, <br></em>
					<i><strong>arXiv</strong>, arXiv:2105.02668.</i>
					<a href="https://arxiv.org/abs/2105.02668" target="_blank">[arXiv]</a>
				</li>

				<li>"Adversarial Exposure Attack on Diabetic Retinopathy Imagery", <br>
					<em>Yupeng Cheng, Felix Juefei-Xu, Qing Guo, <u>Huazhu Fu</u>, Xiaofei Xie, Shang-Wei Lin, Weisi Lin, and Yang Liu, <br></em>
					<i><strong>arXiv</strong>, arXiv:2009.09231.</i>
					<a href="https://arxiv.org/abs/2009.09231" target="_blank">[arXiv]</a>
				</li>


				<li>"Making Images Undiscoverable from Co-Saliency Detection", <br>
					<em>Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, <u>Huazhu Fu</u>, Wei Feng, Yang Liu, and Song Wang, <br></em>
					<i><strong>arXiv</strong>, arXiv:2009.09258.</i>
					<a href="https://arxiv.org/abs/2009.09258" target="_blank">[arXiv]</a>
				</li>



				<li>"DONet: Dual-Octave Network for Fast MR Image Reconstruction", <br>
					<em>Chun-Mei Feng, Zhanyuan Yang, <u>Huazhu Fu</u>, Yong Xu, Jian Yang, and Ling Shao, <br></em>
					<i><strong>arXiv</strong>, arXiv:2105.05980.</i>
					<a href="https://arxiv.org/abs/2105.05980" target="_blank">[arXiv]</a> 
				</li>

				<li>"Re-thinking Co-Salient Object Detection", <br>
					<em>Deng-Ping Fan, Tengpeng Li, Zheng Lin, Ge-Peng Ji, Dingwen Zhang, Ming-Ming Cheng, <u>Huazhu Fu</u>, and Jianbing Shen, <br></em>
					<i><strong>IEEE TPAMI</strong>, in press.</i>
					<a href="https://arxiv.org/abs/2007.03380" target="_blank">[arXiv]</a>
					<a href="http://dpfan.net/wp-content/uploads/TPAMI2021_CoSOD3k-CN.pdf" target="_blank">[Chinese version]</a>
					<a href="https://dpfan.net/CoSOD3K" target="_blank">[Project]</a>
				</li>

				<li>"Salient Object Detection in the Deep Learning Era: An In-Depth Survey", <br>
					<em>Wenguan Wang, Qiuxia Lai, <u>Huazhu Fu</u>, Jianbing Shen, Haibin Ling, and Ruigang
						Yang,<br></em>
					<i><strong>IEEE TPAMI</strong>, in press.</i>
					<a href="https://arxiv.org/abs/1904.09146" target="_blank">[arXiv]</a> <a
						href="https://github.com/wenguanwang/SODsurvey" target="_blank">[Project]</a>
				</li>

				<li>"Deep Partial Multi-View Learning",<br>
					<em>Changqing Zhang, Yajie Cui, Zongbo Han, Joey Tianyi Zhou, <u>Huazhu Fu</u>, and Qinghua
						Hu,<br></em>
					<i><strong>IEEE TPAMI</strong>, in press.</i>
					<a href="https://arxiv.org/abs/2011.06170" target="_blank">[arXiv]</a>
					<a href="https://github.com/hanmenghan/CPM_Nets" target="_blank">[Code]</a>
				</li>
 

			</ul>

			<h4>
				2021:
			</h4>

			<ul>
				<li>"CABNet: Category Attention Block for Imbalanced Diabetic Retinopathy Grading",<br>
					<em>Along He, Tao Li, Ning Li, Kai Wang, and <u>Huazhu Fu</u>,<br></em>

					<i><strong>IEEE TMI</strong>, 2021.</i>
					<a href="https://doi.org/10.1109/TMI.2020.3023463" target="_blank">[Paper]</a>
					<a href="https://github.com/he2016012996/CABnet" target="_blank">[Code]</a>
				</li>

				<li>"Modeling and Enhancing Low-quality Retinal Fundus Images",<br>
					<em>Ziyi Shen, <u>Huazhu Fu</u>, Jianbing Shen, and Ling Shao,<br></em>

					<i><strong>IEEE TMI</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2005.05594" target="_blank">[arXiv]</a>
					<a href="https://github.com/HzFu/EyeQ_Enhancement" target="_blank">[Code]</a>
				</li>

				<li>"ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New Model",<br>
					<em>Yuhui Ma, Huaying Hao, Jianyang Xie, <u>Huazhu Fu</u>, Jiong Zhang, Jianlong Yang, Zhen Wang,
						Jiang
						Liu, Yalin Zheng, and Yitian Zhao,<br></em>

					<i><strong>IEEE TMI</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2007.05201" target="_blank">[arXiv]</a>
					<a href="https://github.com/iMED-Lab/OCTA-Net-OCTA-Vessel-Segmentation-Network"
						target="_blank">[Code]</a>
					<a href="https://imed.nimte.ac.cn/dataofrose.html" target="_blank">[Data]</a>
				</li>

				<li>"Contrast-Attentive Thoracic Disease Recognition with Dual-Weighting Graph Reasoning",<br>
					<em>Yi Zhou, Tianfei Zhou, Tao Zhou, <u>Huazhu Fu</u>, and Ling Shao,<br></em>

					<i><strong>IEEE TMI</strong>, 2021.</i>
					<a href="https://doi.org/10.1109/TMI.2021.3049498" target="_blank">[Paper]</a>
				</li>

				<li>"Applications of Deep Learning in Fundus Images: A Review",<br>
					<em>Tao Li, Wang Bo, Chunyu Hu, Hong Kang, Hanruo Liu, Kai Wang, and <u>Huazhu Fu</u>,<br></em>

					<i><strong>MedIA</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2101.09864" target="_blank">[arXiv]</a>
					<a href="https://github.com/nkicsl/Fundus_Review" target="_blank">[Project]</a>
				</li>


				<li>"Global Guidance Network for Breast Lesion Segmentation in Ultrasound Images",<br>
					<em>Cheng Xue, Lei Zhu, <u>Huazhu Fu</u>, Xiaowei Hu, Xiaomeng Li, Hai Zhang, and Pheng-Ann
						Heng,<br></em>

					<i><strong>MedIA</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2104.01896" target="_blank">[arXiv]</a>
				</li>

				<li>"Deep Triplet Hashing Network for Case-based Medical Image Retrieval",<br>
					<em>Jiansheng Fang, <u>Huazhu Fu</u>, and Jiang Liu,<br></em>

					<i><strong>MedIA</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2101.12346" target="_blank">[arXiv]</a>
					<a href="https://github.com/fjssharpsword/ATH" target="_blank">[Code]</a>
				</li>

				<li>"Trusted Multi-View Classification",<br>
					<em>Zongbo Han, Changqing Zhang, <u>Huazhu Fu</u>, and Joey Tianyi Zhou,<br></em>

					<i><strong>ICLR</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2102.02051" target="_blank">[arXiv]</a>

				</li>

				<li>"Group Collaborative Learning for Co-Salient Object Detection",<br>
					<em>Qi Fan, Deng-Ping Fan, <u>Huazhu Fu</u>, Chi-Keung Tang, Ling Shao, and Yu-Wing Tai,<br></em>

					<i><strong>CVPR</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2104.01108" target="_blank">[arXiv]</a>
					<a href="https://github.com/fanq15/GCoNet" target="_blank">[Code]</a>
				</li>
				<li>"Triple-cooperative Video Shadow Detection",<br>
					<em>Zhihao Chen, Liang Wan, Lei Zhu, Jia Shen, <u>Huazhu Fu</u>, Wennan Liu, and Jing Qin,<br></em>

					<i><strong>CVPR</strong>, 2021.</i>
					<a href="https://arxiv.org/abs/2103.06533" target="_blank">[arXiv]</a>
					<a href="https://erasernut.github.io/ViSha.html" target="_blank">[Project]</a>
					<a href="https://github.com/eraserNut/ViSha" target="_blank">[Code]</a>
				</li>

			</ul>
			<h4>
				2020:
			</h4>

			<ul>
				<li>"Generalized Latent Multi-view Subspace Clustering",<br>
					<em>Changqing Zhang, <u>Huazhu Fu</u>, Qinghua Hu, Xiaochun Cao, Yuan Xie, Dacheng Tao, and
						Dong Xu, <br></em>

					<i><strong>IEEE TPAMI</strong>, 2020.</i>
					<a href="https://dx.doi.org/10.1109/TPAMI.2018.2877660" target="_blank">[Paper]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LMSC_CVPR2017_Zhang.rar">[Code]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar">[Data]</a>
					<font color="#E74C3C"><em>"ESI Highly Cited Paper"</em></font>
				</li>
				<li>"Tensorized Multi-View Subspace Representation Learning",<br>
					<em>Changqing Zhang, <u>Huazhu Fu</u>, Jing Wang, Qinghua Hu, Xiaochun Cao, and Wen Li,<br></em>

					<i><strong>IJCV</strong>, 2020.</i>
					<a href="https://doi.org/10.1007/s11263-020-01307-0" target="_blank">[Paper]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LT-MSC-ICCV15-final.rar">[Code]</a>
				</li>
				<li>"Noise Adaptation Generative Adversarial Network for Medical Image
					Analysis",<br>
					<em>Tianyang Zhang, Jun Cheng, <u>Huazhu Fu</u>, Zaiwang Gu, Yuting Xiao, Kang Zhou, Shenghua Gao,
						Rui
						Zheng, and Jiang Liu,<br></em>

					<i><strong>IEEE TMI</strong>, 2020.</i>
					<a href="https://doi.org/10.1109/TMI.2019.2944488" target="_blank">[Paper]</a>
				</li>
				<li>"Inf-Net: Automatic COVID-19 Lung Infection Segmentation from CT Images",<br>
					<em>Deng-Ping Fan, Tao Zhou, Ge-Peng Ji, Yi Zhou, Geng Chen, <u>Huazhu Fu</u>, Jianbing Shen, and
						Ling Shao,<br></em>

					<i><strong>IEEE TMI</strong>, 2020.</i>
					<a href="https://arxiv.org/abs/2004.14133" target="_blank">[arXiv]</a>
					<a href="https://github.com/DengPingFan/Inf-Net" target="_blank">[Code]</a>
					<font color="#E74C3C"><em>"ESI Highly Cited Paper"</em></font>
				</li>
				<li>"Hi-Net: Hybrid-fusion Network for Multi-modal MR Image Synthesis",<br>
					<em>Tao Zhou, <u>Huazhu Fu</u>, Jianbing Shen, Geng Chen, and Ling Shao, <br></em>
					<i><strong>IEEE TMI</strong>, 2020.</i>
					<a href="https://arxiv.org/abs/2002.05000" target="_blank">[arXiv]</a>
					<a href="https://github.com/taozh2017/HiNet" target="_blank">[Code]</a>
				</li>
				<li>"AGE Challenge: Angle Closure Glaucoma Evaluation in Anterior Segment Optical Coherence
					Tomography",<br>
					<em><u>Huazhu Fu</u>, Fei Li, Xu Sun, and et.al.,<br></em>

					<i><strong>MedIA</strong>, 2020.</i>
					<a href="https://arxiv.org/abs/2005.02258" target="_blank">[arXiv]</a> <a
						href="https://age.grand-challenge.org" target="_blank">[Challenge Link]</a>
				</li>
				<li>"REFUGE Challenge: A Uniﬁed Framework for Evaluating Automated Methods for Glaucoma Assessment from
					Fundus Photographs",<br>
					<em>José Ignacio Orlando, <u>Huazhu Fu</u>, João Barbossa Breda, and <em>et.al.</em>,<br></em>

					<i><strong>MedIA</strong>, 2020.</i>
					<a href="https://arxiv.org/abs/1910.03667" target="_blank">[arXiv]</a>
					<a href="https://refuge.grand-challenge.org/home/" target="_blank">[Challenge Link]</a>
					<font color="#E74C3C"><em>"ESI Highly Cited Paper"</em></font>
				</li>

				<li>"CS^2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical Imaging",<br>
					<em>Lei Mou, Yitian Zhao, <u>Huazhu Fu</u>, Yonghuai Liu, Jun Cheng, Yalin Zheng, Pan Su, Jianlong
						Yang,
						Li Chen, Alejandro F. Frangi, Masahiro Akiba, and Jiang Liu,<br></em>

					<i><strong>MedIA</strong>, 2020.</i>
					<a href="https://arxiv.org/abs/2010.07486" target="_blank">[arXiv]</a>
					<a href="https://github.com/iMED-Lab/CS-Net" target="_blank">[Code]</a>
				</li>

				<li>"Text Co-detection in Multi-view Scene",<br>
					<em>Chuan Wang, <u>Huazhu Fu</u>, Liang Yang, and Xiaochun Cao,<br></em>

					<i><strong>IEEE TIP</strong>, 2020.</i>
					<a href="https://doi.org/10.1109/TIP.2020.2973511" target="_blank">[Paper]</a>
				</li>


				<li>"Multi-mutual Consistency Induced Transfer Subspace Learning for Human Motion Segmentation",<br>
					<em>Tao Zhou, <u>Huazhu Fu</u>, Chen Gong, Jianbing Shen, Ling Shao, and Fatih Porikli,<br></em>

					<i><strong>CVPR</strong>, 2020.</i>
					<a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Zhou_Multi-Mutual_Consistency_Induced_Transfer_Subspace_Learning_for_Human_Motion_Segmentation_CVPR_2020_paper.html"
						target="_blank">[Paper]</a>
				</li>

				<li>"Taking a Deeper Look at the Co-salient Object Detection",<br>
					<em>Deng-Ping Fan, Zheng Lin, Ge-Peng Ji, Dingwen Zhang, <u>Huazhu Fu</u>, and Ming-Ming
						Cheng,<br></em>

					<i><strong>CVPR</strong>, 2020.</i>
					<a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Fan_Taking_a_Deeper_Look_at_Co-Salient_Object_Detection_CVPR_2020_paper.html"
						target="_blank">[Paper]</a>
					<a href="http://dpfan.net/wp-content/uploads/CVPR2020_CoSOD3k_Chinese-final.pdf"
						target="_blank">[Chinese version]</a>
					<a href="http://dpfan.net/CoSOD3k/" target="_blank">[Project]</a>
				</li>

				<li>"NuI-Go: Recursive Non-Local Encoder-Decoder Network for Retinal Image Non-Uniform Illumination
					Removal",<br>
					<em>Chongyi Li, <u>Huazhu Fu</u>, Runmin Cong, Zechao Li, and Qianqian Xu,<br></em>

					<i><strong>ACM MM</strong>, 2020.</i>
					<a href="https://arxiv.org/abs/2008.02984" target="_blank">[arXiv]</a>
					<a href="https://li-chongyi.github.io/Proj_ACMMM20_NuI-Go" target="_blank">[Project]</a>
				</li>
			</ul>

			<h4>
				2019:
			</h4>

			<ul>
				<li>"A Deep Learning System for Automated Angle-Closure Detection in Anterior Segment Optical Coherence
					Tomography Images",<br>
					<em><u>Huazhu Fu</u>, Mani Baskaran, Yanwu Xu, Stephen Lin, Damon Wing Kee Wong, Jiang Liu, Tin A.
						Tun,
						Meenakshi Mahesh, Shamira A. Perera, and Tin Aung,<br></em>

					<i><strong>American Journal of Ophthalmology</strong>, 2019.</i>
					<a href="https://doi.org/10.1016/j.ajo.2019.02.028" target="_blank">[Paper]</a>
				</li>

				<li>"CE-Net: Context Encoder Network for 2D Medical Image Segmentation",<br>
					<em>Zaiwang Gu, Jun Cheng, <u>Huazhu Fu</u>, Kang Zhou, Huaying Hao, Yitian Zhao, Tianyang Zhang,
						Shenghua Gao, and Jiang Liu,<br></em>

					<i><strong>IEEE TMI</strong>, 2019.</i>
					<a href="https://arxiv.org/abs/1903.02740" target="_blank">[arXiv]</a>
					<a href="https://github.com/Guzaiwang/CE-Net" target="_blank">[Code]</a>
					<font color="#E74C3C"><em>"ESI Highly Cited Paper"</em></font>
				</li>

				<li>"Multi-View Saliency-Guided Clustering for Image Cosegmentation",<br>
					<em>Zhiqiang Tao, Hongfu Liu, <u>Huazhu Fu</u>, and Yun Fu,<br></em>

					<i><strong>IEEE TIP</strong>, 2019.</i>
					<a href="https://doi.org/10.1109/TIP.2019.2913555" target="_blank">[Paper]</a>
				</li>

				<li>"Video Saliency Detection via Sparsity-based Reconstruction and Propagation",<br>
					<em>Runmin Cong, Jianjun Lei, <u>Huazhu Fu</u>, Fatih Porikli, Qingming Huang, and Chunping
						Hou,<br></em>

					<i><strong>IEEE TIP</strong>, 2019.</i>
					<a href="https://doi.org/10.1109/TIP.2019.2910377" target="_blank">[Paper]</a>
					<a href="https://github.com/rmcong/Code-for-SRP-Method" target="_blank">[Code]</a>
				</li>

				<li>"Hierarchical Features Driven Residual Learning for Depth Map Super-Resolution",<br>
					<em>Chunle Guo, Chongyi Li, Jichang Guo, Runmin Cong, <u>Huazhu Fu</u>, and Ping Han,<br></em>

					<i><strong>IEEE TIP</strong>, 2019.</i>
					<a href="https://doi.org/10.1109/TIP.2018.2887029" target="_blank">[Paper]</a>
					<a href="https://li-chongyi.github.io/proj_SR.html" target="_blank">[Code]</a>
				</li>

				<li>"CPM-Nets: Cross Partial Multi-View Networks",<br>
					<em>Changqing Zhang, Zongbo Han, Yajie Cui, <u>Huazhu Fu</u>, Joey Tianyi Zhou, and Qinghua
						Hu,<br></em>
					<i><strong>NeurIPS</strong>, 2019.</i>
					<a href="https://papers.nips.cc/paper/2019/file/11b9842e0a271ff252c1903e7132cd68-Paper.pdf"
						target="_blank">[Paper]</a>
					<a href="https://github.com/hanmenghan/CPM_Nets" target="_blank">[Code]</a>
					<font color="#E74C3C">(<em>Spotlight</em>, ~ 2.4%)</font>
				</li>

				<li>"AE^2-Nets: Autoencoder in Autoencoder Networks",<br>
					<em>Changqing Zhang, Yeqing Liu, and <u>Huazhu Fu</u>,<br></em>

					<i><strong>CVPR</strong>, 2019.</i>
					<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_AE2-Nets_Autoencoder_in_Autoencoder_Networks_CVPR_2019_paper.pdf"
						target="_blank">[Paper]</a>
					<a href="https://github.com/willow617/AE2-Nets" target="_blank">
						[Code]
					</a>
					<font color="#E74C3C">(<em>Oral</em>, ~ 5.6%)</font>
				</li>

				<li>"Reciprocal Multi-Layer Subspace Learning for Multi-View Clustering",<br>
					<em>Ruihuang Li, Changqing Zhang, <u>Huazhu Fu</u>, Xi Peng, Joey Tianyi Zhou, and Qinghua
						Hu,<br></em>

					<i><strong>ICCV</strong>, 2019.</i>
					<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Reciprocal_Multi-Layer_Subspace_Learning_for_Multi-View_Clustering_ICCV_2019_paper.pdf"
						target="_blank">[Paper]</a>
				</li>
				<li>"A Deep Step Pattern Representation for Multimodal Retinal Image Registration",<br>
					<em>Jimmy Lee, Peng Liu, Jun Cheng, and <u>Huazhu Fu</u>,<br></em>

					<i><strong>ICCV</strong>, 2019.</i>
					<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_A_Deep_Step_Pattern_Representation_for_Multimodal_Retinal_Image_Registration_ICCV_2019_paper.pdf"
						target="_blank">[Paper]</a>
				</li>

			</ul>

			<h4>
				2018:
			</h4>

			<ul>

				<li>"Joint Optic Disc and Cup Segmentation Based on Multi-label Deep Network and Polar
					Transformation",<br>
					<em><u>Huazhu Fu</u>, Jun Cheng, Yanwu Xu, Damon Wing Kee Wong, Jiang Liu, and Xiaochun
						Cao,<br></em>

					<i><strong>IEEE TMI</strong>, 2018.</i>
					<a href="https://arxiv.org/abs/1801.00926" target="_blank">[arXiv]</a>
					<a href="https://github.com/HzFu/MNet_DeepCDR" target="_blank">[Code]</a>
					<font color="#E74C3C"><em>"ESI Highly Cited Paper"</em></font>
				</li>


				<li>"Disc-aware Ensemble Network for Glaucoma Screening from Fundus Image",<br>
					<em><u>Huazhu Fu</u>, Jun Cheng, Yanwu Xu, Changqing Zhang, Damon Wing Kee Wong, Jiang Liu,
						and Xiaochun Cao,<br></em>

					<i><strong>IEEE TMI</strong>, 2018.</i>
					<a href="http://arxiv.org/abs/1805.07549" target="_blank">[arXiv]</a>
					<a href="https://github.com/HzFu/DENet_GlaucomaScreen" target="_blank">
						[Code]
					</a>
				</li>

				<li>"Structure-preserving Guided Retinal Image Filtering and Its Application for Optic Disc
					Analysis",<br>
					<em>Jun Cheng, Zhengguo Li, Zaiwang Gu, <u>Huazhu Fu</u>, Damon Wing Kee Wong, and Jiang
						Liu,<br></em>

					<i><strong>IEEE TMI</strong>, 2018.</i>
					<a href="https://arxiv.org/abs/1805.06625" target="_blank">[arXiv]</a>
					<a href="https://github.com/samjuncheng/structure-preserving-guided-retinal-image-filtering"
						target="_blank">
						[Code]
					</a>
				</li>

				<li>"Co-saliency Detection for RGBD Images Based on Multi-constraint Feature Matching and Cross Label
					Propagation",<br>
					<em>Runmin Cong, Jianjun Lei, <u>Huazhu Fu</u>, Qingming Huang, Xiaochun Cao, and Chunping
						Hou,<br></em>

					<i><strong>IEEE TIP</strong>, 2018.</i>
					<a href="https://arxiv.org/abs/1710.05172" target="_blank">[arXiv]</a>
					<a href="https://rmcong.github.io/proj_RGBD_cosal.html" target="_blank">[Project]</a>
				</li>

				<li>"YoTube: Searching Action Proposal via Recurrent and Static Regression Networks",<br>
					<em>Hongyuan Zhu, Romain Vial, Shijian Lu, Xi Peng, <u>Huazhu Fu</u>, Yonghong Tian, and Xianbin
						Cao,<br></em>

					<i><strong>IEEE TIP</strong>, 2018.</i>
					<a href="https://doi.org/10.1109/TIP.2018.2806279" target="_blank">[Paper]</a>
				</li>

			</ul>

			<h4>
				2017:
			</h4>

			<ul>
				<li>"Segmentation and Quantification for Angle-Closure Glaucoma Assessment in Anterior Segment OCT",<br>
					<em><u>Huazhu Fu</u>, Yanwu Xu, Stephen Lin, Xiaoqin Zhang, Damon Wing Kee Wong, Jiang Liu,
						Alejandro F. Frangi, Mani Baskaran, and Tin Aung,<br></em>
					<i><strong>IEEE TMI</strong>, 2017.</i>
					<a href="https://doi.org/10.1109/TMI.2017.2703147" target="_blank">[Paper]</a>
					<a href="https://research.a-star.edu.sg/research/7893/a-bird-s-eye-view-for-improved-diagnosis"
						target="_blank">
						<font color="#E74C3C"></font>
					</a>
				</li>
				<li>"Object-based Multiple Foreground Segmentation in RGBD Video",<br>
					<em><u>Huazhu Fu</u>, Dong Xu, and Stephen Lin,<br></em>

					<i><strong>IEEE TIP</strong>, 2017.</i>
					<a href="http://dx.doi.org/10.1109/TIP.2017.2651369" target="_blank">[Paper]</a>
					<a href="proj_rgbdseg.html" target="_blank">[Project]</a>
				</li>

				<li>"Flexible Multi-view Dimensionality co-Reduction",<br>
					<em>Changqing Zhang, <u>Huazhu Fu</u>, Qinghua Hu, Pengfei Zhu, and Xiaochun Cao,<br></em>

					<i><strong>IEEE TIP</strong>, 2017.</i>
					<a href="http://dx.doi.org/10.1109/TIP.2016.2627806" target="_blank">[Paper]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/McDR.rar" target="_blank">[Code]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar" target="_blank">[Data]</a>
				</li>

				<li>"Latent Multi-view Subspace Clustering",<br>
					<em>Changqing Zhang, Qinghua Hu, <u>Huazhu Fu</u>, Pengfei Zhu, and Xiaochun Cao,<br></em>

					<i><strong>CVPR</strong>, 2017.</i>					
					<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Latent_Multi-View_Subspace_CVPR_2017_paper.html"
						target="_blank">[Paper]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LMSC_CVPR2017_Zhang.rar"
						target="_blank">[Code]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar" target="_blank">[Data]</a>
					<font color="#E74C3C">(<em>Spotlight</em>, ~ 8%)</font>
				</li>

			</ul>

			<h4>
				Before 2016:
			</h4>

			<ul>

				<li>"Object-based Multiple Foreground Video Co-segmentation via Multi-state Selection Graph",<br>
					<em><u>Huazhu Fu</u>, Dong Xu, Bao Zhang, Stephen Lin, and Rabab K. Ward,<br></em>

					<i><strong>IEEE TIP</strong>, 2015.</i>
					<a href="http://dx.doi.org/10.1109/TIP.2015.2442915" target="_blank">[Paper]</a>
					<a href="proj_video_coseg.html">[Project]</a>
					<a href="https://github.com/HzFu/VideoCoSeg_MSG" target="_blank">
						[Code]
					</a>
				</li>


				<li>"Constrained Multi-View Video Face Clustering",<br>
					<em>Xiaochun Cao, Changqing Zhang, Chengju Zhou, <u>Huazhu Fu</u>, and Hassan Foroosh,<br></em>

					<i><strong>IEEE TIP</strong>, 2015.</i>
					<a href="http://dx.doi.org/10.1109/TIP.2015.2463223" target="_blank">[Paper]</a>
					<a href="https://chengjuzhou.bitbucket.io/paper/TIP2015/TIP2015.html" target="_blank">[Project]</a>
					<a href="https://bitbucket.org/chengjuzhou/constrained-multi-view-video-face-clustering"
						target="_blank">[Code]</a>
				</li>


				<li>"Self-adaptively Weighted Co-saliency Detection via Rank Constraint",<br>
					<em>Xiaochun Cao, Zhiqiang Tao, Bao Zhang, <u>Huazhu Fu</u>, and Wei Feng,<br></em>

					<i><strong>IEEE TIP</strong>, 2014.</i>
					<a href="http://dx.doi.org/10.1109/TIP.2014.2332399" target="_blank">[Paper]</a>
					<a href="https://github.com/HzFu/SACS_TIP2014" target="_blank">[Code]</a>
				</li>
				<li>"Cluster-based Co-saliency Detection",<br>
					<em><u>Huazhu Fu</u>, Xiaochun Cao, and Zhuowen Tu,<br></em>

					<i><strong>IEEE TIP</strong>, 2013.</i>
					<a href="http://dx.doi.org/10.1109%2FTIP.2013.2260166" target="_blank">[Paper]</a>
					<a href="https://github.com/HzFu/Cosaliency_tip2013" target="_blank">[Code]</a>
					<font color="#E74C3C"><em>"ESI Highly Cited Paper"</em></font>
				</li>

				<li>"Object-based RGBD Image Co-segmentation with Mutex Constraint",<br>
					<em><u>Huazhu Fu</u>, Dong Xu, Stephen Lin, and Jiang Liu,<br></em>

					<i><strong>CVPR</strong>, 2015.</i>
					<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Fu_Object-Based_RGBD_Image_2015_CVPR_paper.html"
						target="_blank">[Paper]</a>
					<a href="proj_rgbdseg.html">[Project]</a>
				</li>

				<li>"Diversity-induced Multiview Subspace Clustering",<br>
					<em>Xiaochun Cao, Changqing Zhang, <u>Huazhu Fu</u>, Si Liu, and Hua Zhang,<br></em>

					<i><strong>CVPR</strong>, 2015.</i>
					<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Cao_Diversity-Induced_Multi-View_Subspace_2015_CVPR_paper.html"
						target="_blank">[Paper]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/DiMSC.rar" target="_blank">[Code]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar" target="_blank">[Data]</a>
				</li>



				<li>"Low-Rank Tensor Constrained Multiview Subspace Clustering",<br>
					<em>Changqing Zhang, <u>Huazhu Fu</u>, Si Liu, Guangcan Liu, and Xiaochun Cao,<br></em>

					<i><strong>ICCV</strong>, 2015.</i>
					<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhang_Low-Rank_Tensor_Constrained_ICCV_2015_paper.html"
						target="_blank">[Paper]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LT-MSC-ICCV15-final.rar"
						target="_blank">[Code]</a>
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar" target="_blank">[Data]</a>
				</li>

				<li>"Object-based Multiple Foreground Video Co-segmentation",<br>
					<em><u>Huazhu Fu</u>, Dong Xu, Bao Zhang, and Stephen Lin,<br></em>

					<i><strong>CVPR</strong>, 2014.</i>
					<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Fu_Object-based_Multiple_Foreground_2014_CVPR_paper.html"
						target="_blank">[Paper]</a>
				</li>


			</ul>

			<hr />


		</section>

	</div>
</body>

</html>

